---
title: How About That Weather!? - An EDA of Climate Change in Berlin.
author: Gershom Tripp
date: '2018-09-26'
categories:
  - R
tags:
  - Berlin
  - climate
  - EDA
slug: how-about-that-weather-an-eda-of-climate-change-in-berlin
output:
  blogdown::html_page:
    toc: yes
draft: true
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```










# Introduction

In his book [*What We Think About When We Try Not to Think About Global Warming*](https://www.amazon.de/What-Think-About-Global-Warming/dp/1603585834), Per Espen Stoknes writes the following about the role of psychological "distance" when faced with climate change:

> The climate issue remains remote for the majority of us, in a number of ways. We can’t see climate change. Melting glaciers are usually far away, as are the spots on earth now experiencing sea level rise, more severe floods, droughts, fires, and other climate disruptions. It may hit foreign others, not me or my kin. And the heaviest impacts are far off in time—in the coming century or farther. Despite some people stating that global warming is here now, it still feels distant from everyday concerns.

The following [EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis) is in essence a personal first attempt to counteract this tendency.

I absolutely *believe* that I've witnessed the effects of global warming - that is to say, climate change - in the 11+ years that I've lived in Berlin. It snows less, the summers seem warmer, and I don't remember the summer storms being so intense 10 years ago. Albeit, I haven't yet taken the time to confirm my observations with data - an unforgiveable offence for a budding data scientist!

For the record, I'm neither a climatoligist nor a meteorologist, and there's probably nothing about this analysis that is cutting edge or even terribly original. That also isn't my intention. At the moment I'm more interested in conducting a preliminary *exploration* of the data, mostly through the visualization of how certain variables have changed over time. Any insights gleaned should primarily serve to focus later analyses.

That being said, the earth sciences rely on statistical methods just like every other scientific field. So I should, with much googling, eventually be able to reach something resembling a conclusion.

The next couple of sections cover how I wrangle the data into a more manageable form. There's little to see other than code. I've included it for the sake of the learners, critics, and assorted weirdos (Like me!) who are into that kind of thing. If you don't care, just [skip to the analysis](#visualizing-climate-change-in-berlin).










***








# Data Import and Preparation

First off, the libraries:

```{r load-libs, warning=FALSE, error=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(stats)
library(psych)
library(lubridate)
library(ggplot2)
library(corrplot)
```












## Importing

The data is a subset of the [Deutscher Wetterdienst](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klarchivtagmonat.html)'s
extensive repository of weather data. They offer yearly, monthly, weekly, hourly, and even minutely (!?) measurements, going back decades, but I decided daily averages were enough for this analysis. Downloading the data programmatically from the DWD archive interface wouldn't have been practical, so I did it the old-fashioned way: I downloaded the data as four ZIPs (from four Berlin weather stations), extracted the TXT/CSV files, renamed them to something more descriptive, and wrote some code to remove excess white space that was interfering with the data import.

*Edit: While putting the final touches on this post I discovered that the DWD offers FTP access to their databases via the [Climate Data Center](ftp://ftp-cdc.dwd.de/pub/CDC/). I would definitely take this route in future analyses.*

The data files are semicolon-delimited. To keep things simple I'll import everything as character strings. Numeric and date objects are converted later, as needed. The value `-999` is imported as `NA`. There is a warning because of some extra columns (not printed here), but it doesn't effect the import.

```{r remove-whitespace, message=FALSE}
# get the names of  the data files, import them as text, remove white space and
# overwrite originals with de-whitespaced files
data_path <- file.path("datasets", "berlin_climate_data")
file_names <- dir(data_path)
file_names <- file_names[grep(pattern = "data", file_names)]

for (file_name in file_names){
    file_path <- file.path(data_path, file_name)
    file <- read_file(file_path)
    file <- gsub(" ", "", file)
    write_file(file, file_path)
}

# wrapper function to load data with defaults
read_data <- function(path){
    read_delim(file = path,
               delim = ";",
               col_types = paste0(rep("c", 19), collapse = ""),
               na = "-999"
               )
}

# read in the data
dahlem_fu_data <- read_data(file.path(data_path, "Dahlem-(FU)-data.txt"))
dahlem_lfag_data <- read_data(file.path(data_path, "Dahlem-(LFAG)-data.txt"))
tegel_data <- read_data(file.path(data_path, "Tegel-data.txt"))
tempelhof_data <- read_data(file.path(data_path, "Tempelhof-data.txt"))
```


It makes sense to take a look at the included parameter files to get an idea what kind of data I'm working with. These are in German (umlauts!), so I'll use `guess_encoding()` from the `readr` library to figure out which ISO I need.

```{r guess-encoding}
guess_encoding("datasets/berlin_climate_data/Dahlem-(FU)-params.txt") %>% 
    knitr::kable()
```

ISO-8859-1 it is. I don't care too much about the details of each station, so I'll just import one file, `Tempelhof-params.txt`, to gain some insight into the parameters, i.e. abbreviations, units used, etc. 

```{r load-show-params, warning=FALSE}
# load parameter file
data_path <- file.path("datasets", "berlin_climate_data", "Tempelhof-params.txt")
tempelhof_params <- read_delim(file = data_path,
                               delim = ";",
                               col_types = paste0(rep("c", 13), collapse = ""),
                               locale = locale(encoding = "ISO-8859-1")
                               )

# filter and show parameters
tempelhof_params %>%
    select(2:7) %>% 
    filter(!duplicated(Parameter) & !is.na(Parameter)) %>% 
    knitr::kable()
```












## Tidying

There are a couple more changes to be made before I can start visualizing. First, [tidyverse](https://www.tidyverse.org/) magic works most potently on *long* data, but the DW uses *wide* format ([see the difference here](https://en.wikipedia.org/wiki/Wide_and_narrow_data)). Second, the variable abbreviations are hard to understand (FM, RSK, etc.), so I'll replace them with something else. Third and last, I have four datasets right noew, one for each Berlin weather station, but one would be preferable.

I'll change the variable names using the following map.

```{r names-map}
var_names <- c("Date" = "MESS_DATUM",
               "Avg. Wind Speed (m/sec)" = "FM",
               "Max Wind Speed (m/sec)" = "FX",
               "Avg. Cloud Cover (8th)" = "NM",
               "Avg. Air Pressure (hPa)" = "PM",
               "Precipitation (mm)" = "RSK",
               "Sunshine Duration (h)" = "SDK",
               "Snow (cm)" = "SHK_TAG",
               "Avg. Temp. (°C)" = "TMK",
               "Min. Temp. (°C)" = "TNK",
               "Max Temp. (°C)" = "TXK",
               "Avg. Rel. Humidity (%)" = "UPM",
               "Avg. Vapor Pressure (hPa)" = "VPM"
               )
```

The following `tidy_data` function reduces each data frame to the set of variables I'm interested in, converts the character strings to numbers and dates, and `gathers` the variables into long format.

```{r function-tidy-data}
tidy_data <- function(df, vars, station_name){
    df <- select(df, vars)
    df <- as_tibble(sapply(df, as.double))
    df$Date <- ymd(df$Date)
    df <- gather(df, key = "Variable", value = "Value", 2:13)
    df$Station <- station_name
    df
}
```

I can now call `tidy_data` for each station, and then combine the station data into one data frame `berlin_data`.

```{r tidy-stations}
# call tidy_data for each station dataset
dahlem_lfag_data <- tidy_data(dahlem_lfag_data, var_names, "Dahlem (LFAG)")
dahlem_fu_data <- tidy_data(dahlem_fu_data, var_names, "Dahlem (FU)")
tegel_data <- tidy_data(tegel_data, var_names, "Tegel")
tempelhof_data <- tidy_data(tempelhof_data, var_names, "Tempelhof")

# combine station data into one data frame
berlin_data <- rbind(dahlem_lfag_data, dahlem_fu_data, tegel_data, tempelhof_data)
```

There is just one final change I would like to make: The values reflect daily averages, and measurement began in the 19th century for some stations, so I'm faced with hundreds of thousands of observations! To make things more manageable I'll include different time scales, e.g. years, months, weeks, days, and [meteorological seasons](https://en.wikipedia.org/wiki/Season#Meteorological), to group the individual dates. While I'm at it I'll also convert months and seasons to factors.

```{r add-time-units}
# add years, months, weeks, days, and seasons
berlin_data <- berlin_data %>% 
    mutate(Year = year(Date),
           Month = month(Date),
           Week = week(Date),
           Day = day(Date),
           Season = case_when(Month %in% c(12, 1, 2) ~ "Winter",
                              Month %in% 3:5 ~ "Spring",
                              Month %in% 6:8 ~ "Summer",
                              Month %in% 9:11 ~ "Fall",
                              )
           )

# turn seasons into factors
berlin_data$Season <- factor(berlin_data$Season,
                             ordered = T,
                             levels = c("Spring", "Summer", "Fall", "Winter")
                             )
berlin_data$Station <- factor(berlin_data$Station,
                             ordered = T,
                             levels = c("Dahlem (LFAG)", "Dahlem (FU)", "Tempelhof", "Tegel")
                             )

# turn months into factors
berlin_data$Month <- factor(berlin_data$Month,
                            ordered = T,
                            levels = 1:12,
                            labels = c("January", "February", "March", "April",
                                       "May", "June", "July", "August", 
                                       "September", "October", "November",
                                       "December"
                                       )
                            )
```











***




```{r}
berlin_data %>% 
    select(Date, Variable, Value, Station) %>% 
    spread(Variable, Value) %>% 
    group_by(Station) %>% 
    summary()
```






# Visualizing Climate Change in Berlin

I now have a few hundred thousand observations for each of four Berlin weather stations, which I can freely group based on my analytical needs. The following table shows the total observations (daily averages) for each of Berlin's four weather stations.

```{r show-observations}
berlin_data %>% 
    group_by(Station) %>% 
    summarise("number of observations" = n()) %>% 
    knitr::kable()
```











## Average Annual Temperature: Berlin

My first question is: How have average annual temperatures changed since 1876? The following time series shows that temperatures in Berlin have increased by about 2°C, on average, with the warming rate apparently accelerating from about the middle of the last century. There is quite a bit of variation, but the general trend is unmistakable. 
 
```{r viz-yearly-temps, message=FALSE}
# create variable to hold theme (reusable)
thm <- theme_minimal() + 
    theme(panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank()
          )

# generate combined timeseries of temperatur data
berlin_data %>% 
    filter(Variable == "Avg. Temp. (°C)") %>%
    group_by(Station, Year) %>% 
    summarise(Value = mean(Value, na.rm = T)) %>%
    ggplot(aes(x = Year, y = Value)) +  
    geom_line(aes(color = Station)) +
    scale_color_manual(values = c("#000000", "#000090", "#4848ED", "#8888FF")) +
    geom_smooth(se = F, method = "loess", span = .8, color = "#FF0000") +
    labs(title = "Avg. Yearly Temperature (°C), 1877-2017",
         y = "Temp."
         ) +
    thm +
    scale_x_continuous(limits = c(1876, 2017),
                       breaks = seq(1877, 2017, by = 10)
                       ) +
    scale_y_continuous(limits = c(3, 12),
                       breaks = seq(3, 12, by = 1)
                       )
```

Also conspicuous is the precipitous drop in 1945. Histograms of each year from 1941-1949 reveal bimodal distributions of daily temperatures for most years. One mode is missing from 1945, that is to say, some data is missing, and the data that is available clusters around the low end.

```{r viz-temps-distribution}
berlin_data %>% 
    filter(Station == "Dahlem (LFAG)",
           Variable == "Avg. Temp. (°C)",
           Year %in% 1941:1949,
           !is.na(Value)
           ) %>% 
    ggplot(aes(x = Value)) + 
    geom_histogram(bins = 30) +
    facet_wrap(~Year) + 
    theme_minimal() + 
    theme(panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.spacing = unit(2, "lines")
          ) +
    labs(title = "Distribution of Annual Temperatures (°C), 1941-1949",
         x = "Temperature"
         )
```

A table of observation counts (i.e. number of daily averages) confirms that 1945 is missing data.

```{r table-temps-distribution}
berlin_data %>% 
    filter(Station == "Dahlem (LFAG)",
           Variable == "Avg. Temp. (°C)",
           Year %in% 1941:1949,
           !is.na(Value)
           ) %>% 
    group_by(Year) %>% 
    summarize("number of obs." = n(),
              "annual avg. temp." = mean(Value)) %>% 
    knitr::kable()
```

The [Battle of Berlin](https://en.wikipedia.org/wiki/Battle_of_Berlin) was in the spring of 1945, so there's really no question as to why the data is missing. I could go to the trouble of interpolating values from the flanking years, but I'll save myself some time and just drop 1945 instead, which shouldn't have any effect on the overall trend. I'll also aggregate the station data to make later visualizations a little easier.

```{r drop-1945}
berlin_data <- filter(berlin_data, Year != 1945) %>% 
    group_by(Year, Month, Week, Day, Season, Date, Variable) %>% 
    summarise(Value = mean(Value, na.rm = T)) %>% 
    ungroup()
```













## Average Annual Temperature: Global vs. Local


The next chart compares changes in Berlin's average yearly temperature with global temperature shifts. First, I need to download some data of global historical temperatures from [NASA](https://climate.nasa.gov/vital-signs/global-temperature/).

```{r get-nasa-data}
nasa_data <- read_tsv("https://climate.nasa.gov/system/internal_resources/details/original/647_Global_Temperature_Data_File.txt",
                      col_names = c("Year", "World", "lowess"),
                      col_types = "idd"
                      )
```


I can then combine the NASA data with the Berlin data and visualize them together. The following graph shows the trend in global annual means compared to Berlin's. Note that the y-axis displays average annual temperature *change* in °C, and *not* average annual temperature. What I call change NASA calls *annual average anomaly*, which is the "change in global surface temperature relative to 1951-1980 average temperatures". To maintain consistency with NASA's data I'll also transform the Berlin data to also represent the change from the 1951-1980 average. Also note that I plot Loess curves to cut out the noise, but use `span = 0.2` so the variation is completely lost.

```{r viz-global-vs-berlin}
berlin_data %>%
    filter(Variable == "Avg. Temp. (°C)",
           ) %>%
    group_by(Year) %>%
    summarise(Value = mean(Value, na.rm = T)) %>%
    
    # put Berlin data in relation to 1951-1980 average
    mutate(Berlin = Value - mean(filter(.data = .,
                                        Year %in% 1951:1980
                                        )[["Value"]]
                                 )
           ) %>%  
    right_join(nasa_data, by = "Year") %>%
    select(Year, Berlin, World) %>%
    filter(!is.na(Berlin), !is.na(World)) %>% 
    
    # loess transform
    mutate(Berlin = predict(loess(Berlin ~ Year, data = ., span = 0.2)),
           World = predict(loess(World ~ Year, data = ., span = 0.2))
           ) %>% 
    
    # tidy and plot
    gather(key = "Scope", value = "Value", 2:3) %>%
    ggplot(aes(x = Year, y= Value)) +
    geom_line(aes(color = Scope), size = 1) +
    geom_hline(yintercept = 0, linetype = 8) +
    thm + 
    scale_x_continuous(limits = c(1876, 2017),
                       breaks = seq(1877, 2017, by = 10)
                       ) +
    scale_y_continuous(limits = c(-1, 2),
                       breaks = seq(-1, 2, .5)) +
    scale_color_manual(values = c("red", "blue")) +
    labs(color = "",
         title = "Annual Avg. Anomaly (LOESS), World vs. Berlin, 1877-2017",
         y = "Change (°C)"
         )
```

The upward trend in mean annual temperature in Berlin broadly parallels that of the global aggregate. Interestingly, the annual mean seems to be increasing faster in Berlin than it is globally - approximately 2°C vs. 1°C.  This is likely due to the [urban heat island effect](https://en.wikipedia.org/wiki/Urban_heat_island).











## An Overview of Selected Variables

The rest of the analysis focusses on the last six decades - mostly because the greatest increase in mean annual temperature occurred in that period, but also because the data from the prior years aren't complete.

The next three plots display the trends of 9 variables of interest. The first two are identical except of the choice of smoother: The first uses linear models to capture the overall six-decade trend, and the second uses LOESS to help get a fix on shorter trends that might still be very relevant.

```{r subset-viz-all-lm, fig.width=10, fig.height=10}
# create a subset for 1957-2017, and 9 variables
berlin_subset <- berlin_data %>% 
    filter(Year > 1956, complete.cases(.)) %>% 
    filter(Variable %in% c("Avg. Air Pressure (hPa)",
                           "Avg. Cloud Cover (8th)",
                           "Avg. Rel. Humidity (%)",
                           "Avg. Temp. (°C)",
                           "Avg. Wind Speed (m/sec)",
                           "Precipitation (mm)",
                           "Snow (cm)",
                           "Sunshine Duration (h)",
                           "Avg. Vapor Pressure (hPa)"
                           )
           )

# plot it
berlin_subset %>% 
    group_by(Year, Variable) %>%  
    summarize(Value = mean(Value, na.rm = T)) %>% 
    ggplot(aes(x = Year, y = Value)) +
    geom_line(alpha = 0.5) +
    geom_smooth(method = "lm", se = F) +
    facet_wrap(~ Variable, scales = "free", ncol = 3) +
    thm +
    theme(panel.spacing = unit(3, "lines")) +
    scale_x_continuous(breaks = seq(1957, 2017, by = 10)) +
    labs(title = "Linear Trends of Selected Variables, 1957-2017")
```

The strongest trends can be seen in average annual temperature and wind speed, the latter of which decreases as the former increases. This is, for me personally, unexpected. There is probably a connection there - for example, warmer weather might lead to more high-pressure fronts, fairer weather and less wind - but I'm not yet sure what it is. Unfortunately, a quick Google search didn't yield anything useful.

It makes sense that there is an inverse relationship between cloud cover and sunshine duration (less clouds = more sunshine). Relative humidity seems to follow a pattern very similar to that of cloud cover, and my rudimentary understanding of the moisture content of air and weather leads me to believe they are related.

A little research reveals that vapor pressure is closely linked to temperature, but things get a little more complicated after that. For instance, I was initially baffled by the fact that humidity can decrease while vapor pressure increases. After watching The Organic Chemistry Tutor's excellent [tutorial](https://www.youtube.com/watch?v=BqFVtlQa-2w) on the relationship between relative humidity and vapor pressure, I think something like the following might be happening (this is a learning process, so bear with me):

Vapor pressure is a function of temperature, i.e. it increases as a direct result of increasing temperature. Relative humidity tells us how much moisture is in the air compared to how much moisture *could* be in the air at a given temperature. Formally, relative humidity is the quotient of the partial pressure of water vapor divided by equilibrium vapor pressure, where the partial pressure of water vapor represents the actual amount of water vapor in the air. Here's the equation (Thanks [Wikipedia](https://en.wikipedia.org/wiki/Relative_humidity)!):

$$
\phi ={\frac {p_{\mathrm {H_{2}O}}}{p_{\mathrm {H_{2}O} }^{*}}}
$$

Rising temperatures cause vapor pressure to rise as well, but partial pressure may increase more slowly or even remain fairly stable, depending on other factors, such the amount of water available in the environment. An increasing $p_{\mathrm {H_{2}O} }^{*}$ and stable $p_{\mathrm {H_{2}O} }$ would drive down the $\phi$, even though the absolute moisture content of the air is actually increasing. 

It turns out that relative humidity is a bit of a [fraught concept](https://www.washingtonpost.com/news/capital-weather-gang/wp/2017/07/12/stop-telling-us-to-use-percent-humidity-its-terrible-and-heres-why/?utm_term=.83775061014a) precisely because it's difficult to interpret. The upshot of the above scenario is that more heat and moisture do [lead to stronger storms](https://earthobservatory.nasa.gov/Features/ClimateStorms/page2.php), but that relative humidity might not be the best indicator for that kind of change.

In the next group of plots is the same as the last, except I've applied a LOESS smoother.

```{r subset-viz-all-loess, fig.width=10, fig.height=10}
berlin_subset %>% 
    group_by(Year, Variable) %>%  
    summarize(Value = mean(Value, na.rm = T)) %>% 
    ggplot(aes(x = Year, y = Value)) +
    geom_line(alpha = 0.5) +
    geom_smooth(method = "loess", se = F) +
    facet_wrap(~ Variable, scales = "free", ncol = 3) +
    thm +
    theme(panel.spacing = unit(3, "lines")) +
    scale_x_continuous(breaks = seq(1957, 2017, by = 10)) +
    labs(title = "Trends of Selected Variables (LOESS), 1957-2017")
```

Cloud cover and humdity are, in fact, increasing as of approximately 1987, and temperature and vapor pressure do not align as neatly as they appear to above. I suspect that relative humidity eventually starts to increase as partial pressure catches up to vapor pressure. Also, it's not far-fetched to believe that the effects of an increase in temperature might lag behind the cause as a result of complexities in the broader system, e.g. mitigating effects of flora, large bodies of water, global weather patterns, etc.

The one variable that seems to contradict my theory is precipitation, which has remained comparatively stable despite a couple of pronounced spikes in the latter years. However, these are annual means, but the types of storm fronts I am concerned with most likely occur in during warmest part of the year. If some other season is drying out as quickly as summer is getting wetter, then the annual mean might remain more or less stable. The next cluster of time series zooms in on annual changes for the months May-August.

```{r subset-viz-summer-loess, fig.width=10, fig.height=10}
berlin_subset %>% 
    filter(Month %in% c("May", "June", "July", "August")) %>% 
    group_by(Year, Variable) %>%  
    summarize(Value = mean(Value, na.rm = T)) %>% 
    ggplot(aes(x = Year, y = Value)) +
    geom_line(alpha = 0.5) +
    geom_smooth(method = "loess", se = F) +
    facet_wrap(~ Variable, scales = "free", ncol = 3) +
    thm +
    theme(panel.spacing = unit(3, "lines")) +
    scale_x_continuous(breaks = seq(1957, 2017, by = 10)) +
    labs(title = "Trends of Selected Variables (LOESS), May-August, 1957-2017")
```

Most of the patterns from above have remained, with the exception that precipitation now shows a trend similar to cloud cover and relative humidity. Precipitation also shows a great deal more variation in the last 10-20 years, which might hint at more extreme weather events (drought vs. torrential rainfall).

The remaining visualizations focus on individual variables. Each group of plots displays shifts in one variable, for each month, over 60 years. I've also grouped them by [meteorological season](https://en.wikipedia.org/wiki/Season#Meteorological), with spring and summer being shades of red, and fall and winter shades of blue.

This bit is just to help me keep the rest a little shorter: 

```{r save-settings}
filter_group <- function(df){
    df %>% filter(Year %in% (1957:2017)) %>%
    group_by(Year, Season, Month)
    }
    
gg_geoms_x_scale <- function(df){
    df %>% ggplot(aes(x = Year, y = Value, color = Season)) +
        geom_line(alpha = .5) +
        geom_smooth(method = "loess", se = F, span = 0.5) +
        scale_color_manual(values = c("#FF9F9F", "#E50000", "#7777FF", "#0000C4")) +
        scale_x_continuous(limits = c(1957, 2017),
                           breaks = seq(1957, 2017, by = 10)
                           ) +
        facet_wrap(~ Month)
}

thm <- thm + 
    theme(panel.spacing = unit(1, "lines"))
```












## Proportion of +25°C Days

Now I can plot the proportion of days per month, for the months May-September, where maximum temperatures exceed 25°C.

```{r viz-temps-25, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Max Temp. (°C)"
           ) %>%
    filter_group() %>% 
    summarise(Value = sum(Value > 25)/n()) %>% 
    gg_geoms_x_scale() +
    scale_y_continuous(limits = c(-0.5, 1),
                       breaks = seq(0, 1, by = .1)
                       ) +
    thm +
    labs(title = "Proportion of Days with Temp. > 25°C, 1957-2017",
         y = "Proportion"
         )
```

Predictably, the proportion of days with maximum temperatures above 25°C has gone up since 1957, particularly in July and August, but also in May and September. The summer months show a great deal of variation over the years. Surprising is the fact that June has remained stable even as other months show dramatic increases.





## Sunshine

Looking at the next set of time series, the average number of hours of daily sunshine appear to have remained fairly stable for most months. There is a long-term increase to be seen in April, and to a lesser degree in March. In June and September there is long decline followed by an ascent to previous levels. There are no obvious downward trends. I take this to mean that any increases in precipitation are not necessarily due to more frequent, or more protracted storms, as these should affect daily sunshine means.

```{r viz-sunshine, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Sunshine Duration (h)") %>%
    filter_group() %>% 
    summarize(Value = mean(Value)) %>% 
    gg_geoms_x_scale() +
    scale_y_continuous(limits = c(0, 12.5),
                       breaks = seq(0, 12, by = 1)
                       ) +
    facet_wrap(~ Month) +
    thm +
    labs(title = "Avg. Daily Sunshine (Hours), 1957-2017",
         y= "Duration (h)"
         )
```






## Precipitation

For the most part the average amount of precipitation also doesn't show any general upward trends since 1957, perhaps with the exception of July. At shorter timescales, however, and for individual months, there are discernible trends. June and July are the wettest months, and seem to be getting even wetter - July since 1970 and June particularly in the last 10-15 years. It also looks like there might be a slight increase in October. A few months also seem to be showing a gradual decrease in the amount of precipitation, but I don't think the data is conclusive in that regard. 

```{r viz-precipitation, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Precipitation (mm)") %>%
    filter_group() %>% 
    summarize(Value = mean(Value)) %>% 
    gg_geoms_x_scale() + 
    scale_y_continuous(limits = c(0, 8),
                       breaks = seq(0, 8, by = 1)) +
    facet_wrap(~ Month) +
    thm + 
    labs(title = "Avg. Daily Precipitation (mm), 1957-2017",
         y= "Amount (mm)"
         )
```







## Days Without Precipitation

The proportion of "dry" (no precipitation) to "wet" (some precipitation) days doesn't show much of a long-term trend for any month, with the exception of April. Over shorter time periods of 20-30 years late winter and spring seem to be becoming drier, while late fall and early winter are getting wetter. A few months also show an interesting looking sinusoid-ish pattern that might indicate some kind of macro-cycle of wet and dry phases.

```{r viz-no-precipitation, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Precipitation (mm)") %>%
    filter_group() %>% 
    summarize(Value = sum(Value == 0)/n()) %>% 
    gg_geoms_x_scale() + 
    scale_y_continuous(limits = c(0, 1),
                       breaks = seq(0, 1, by = .1)) +
    thm +
    labs(title = "Days Without Precipitation as Proportion of all Days, 1957-2017",
         y= "Proportion"
         )
```







### Air Pressure

Given what I know about the dynamic between air pressure and weather (admittedly not that much) I think air pressure could be a further indicator of storm intensity. As I understand it, stable high pressure zones usually indicate good weather while rapidly decreasing air pressure indicates an impending storm. Hourly data are necessary to properly analyze the association between air pressure and bad weather, something I decided against for the this analysis for time reasons. Still, I assume strong storms would leave some trace by driving down daily averages. 

To see if air pressure, measured in hectopascals (hPa), is a good indicator of weather conditions, I'll plot the correlations of some relevant variables in a correlogram. I should note that this probably isn't the best method to determine how air pressure affects weather. Finer-grained air pressure data, and variables more closely associated with bad weather, cloud type for instance, in addition to more rigorous statistical methods and assumption checks would allow me to more confidently draw conclusions. But a heuristic strategy should help me determine if there are any questions worth asking before I invest too much of my precious time.

First I need to compute a correlation matrix. This code *widens* the data by giving each variable it's own column (basically the reverse of the above *tidying* process), and then computes the correlations (Spearman's $\rho$ in this case).

```{r transform-subset-correlation}
berdat_sub <- berlin_data %>%
    filter(Month %in% c("May", "June", "July", "August"),
           Year > 1956) %>%
    spread(Variable, Value) %>% 
    select(7:17, -`Snow (cm)`, -`Avg. Cloud Cover (8th)`)

names(berdat_sub) <- c("PRESS", "HUMID", "TEMP_AVG", "WIND_AVG", "TEMP_MAX",
                       "WIND_MAX", "TEMP_MIN", "PRECIP", "SUN")

berdat_cortest <- corr.test(x = berdat_sub, method = "spearman")
```

I'll use a matrix of *p*-values, conveniently calculated by the `psych` library's `corr.test` function along with the actual correlations, to test for the statistical significance of the individual correlations, as even low correlation can hint at so sort of association. The significance level is set to $\alpha$ = 0.001. 

I should mention that sample size has an affect on *p*-values, so some statistically significant correlations below might not be very meaningful. That said, it can still be helpful. It should also be interesting to see which variables are not significant despite the sample size.

```{r viz-correlogram, fig.width=7, fig.height=7}
corrplot(berdat_cortest$r,
         p.mat = berdat_cortest$p,
         sig.level = .001,
         type = "upper",
         method = "number",
         order = "AOE",
         tl.cex = .8,
         title = "Correlogram (rho) of Selected Variables",
         mar = c(0, 0, 2, 0),
         col = colorRampPalette(c("red", "white", "blue"))(100)
         )
```


Of particular interest are correlations between air pressure (`PRESS`) and the other variables that also make intuitive sense, as that would imply that air pressure is a good predictor of weather conditions. We should expect, for example, that high pressure is positively correlated with fair weather, given by sunshine duration (`SUN`), and negatively correlated with wind and bad weather, as given by maximum and average windspeed (`WIND_MAX` and `WIND_AVG`) and the amount of precipitation (`PRECIP`). Looking at the plot, this seems to be the case, so I'll accept - for the time being, and with the above proviso - that a day's average air pressure can tell me something about the weather conditions for that day.

The final plot displays the number of days per month where there is at least a -3 hPa *drop* in air pressure compared to the previous day. Although this measure is obviously not perfect, my layperson intuition tells me that an increase in the number of such drops might hint at an increase in storm fronts of a certain intensity.

The choice of -3 hPa is not completely arbitrary. A convenient table on [bohlken.net](http://www.bohlken.net/airpressure2.htm) (a barograph maker) states that a drop of -3 hPa can lead to strong winds of 6-7 Bfts (11-17 m/s), so it seems like a decent place to start.

Nevertheless, there are at least two major problems here to keep in mind: First, the table on bohlken.net relates wind speed increases to a drop in air pressure over a 1-3 hour timeframe, while the data I'm using contains 24-hour means. Second, there is an implicit assumption that "bad weather" days and "good weather" days are more or less evenly dispersed, as there wouldn't be any difference between consecutive days of the same type. This is very likely not the case.

Still, I'm fairly confident that larger, more extreme storm fronts would leave a trace on daily hPa averages, and that an increase in the amount or intensity of these fluctuations is measurable. I also think that severe weather is still infrequent enough in Berlin that an increasing number of large drops should show up in monthly aggregates.

The below plot seems to confirm my intuitions. Especially the months May-August show strong upward trends over the last 10-20 years, which I think I can safely interpret as a general intensification of storm strength within that period. 

```{r viz-pressure-drop, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Avg. Air Pressure (hPa)") %>% 
    filter_group() %>% 
    mutate(Value = (Value - lag(Value))) %>%
    filter(!is.na(Value), Value < -3) %>%
    group_by(Year, Season, Month) %>%
    summarize(Value = n()) %>%
    gg_geoms_x_scale() + 
    facet_wrap(~ Month) +
    scale_y_continuous(limits = c(2, 15),
                       breaks = seq(2, 15, by = 1)
                       ) +
    thm + 
    labs(title = "Drop in Air Pressure (hPa) from Previous Day > 3",
         y= "Number of Days"
         )
```

There are a couple of potential pitfalls in this interpretation. First, the upward trend is confined to the period 2000-2017, and it doesn't look like much against the backdrop of the previous four decades. Within that context it might be little more than a hiccup. Second, the increases in May and August aren't entirely consistent with the decreases we see in daily precipitation in those months, which might cast doubt on the whole "air pressure = storm strength" hypothesis. The fact that air pressure is lowest in the summer is [not a surprise](https://www.researchgate.net/post/Why_does_atmospheric_pressure_show_higher_values_in_December_and_loweer_in_July).

I still think there might be a trend here, however, and for the following reasons:

1. Although the trend is localized and unimpressive when seen within the context of the entire six decades, it is consistent across the four warmest months.
2. The overall trends for the individual months show remarkable similarities to the corresponding trends in average daily precipitation, which seems to indicate that these kinds of shifts are an appropriate proxy for weather patterns.
3. Regarding the inconsistencies in May and August: A drastic drop in air pressure can also be a sign of windstorms, or of strong storm fronts that pass over Berlin without leaving much rain behind.
    





***





## Conclusion

As I've already made clear, I can't confidently draw too many conclusions based on the data I have. One exception is the undeniable fact that Berlin is getting warmer. On that the data is unambiguous. It is also [well known](https://earthobservatory.nasa.gov/Features/ClimateStorms/page2.php) that temperature has an effect on weather systems generally, and storm intensity specifically, so it would make sense that this kind of pattern would also develop in a warming Berlin.


Since I mostly rely on indirect measures of storm intensity it's hard to say conclusively if there has been a change, but the data I have seem to indicate that this is very likely. One uncontroversial finding is that vapor pressure has increased as a result of rising temperatures. I think I can also safely say that increasing vapor pressure is . Given the known link between heat, moisture, and storm strength, it shouldn't be too far off the mark to surmise that storms in and around Berlin are increasing in intensity. The data also hint at exactly this development: Precipitation has increased in the warmest months even as the proportion of rainless days and average daily sunshine has remained relatively stable, suggesting that storms have become more intense without necessarily becoming more frequent.






---
title: How About That Weather!? - An EDA of Climate Change in Berlin.
author: Gershom Tripp
date: '2018-09-17'
slug: how-about-that-weather-an-eda-of-climate-change-in-berlin
categories:
  - R
tags:
  - Berlin
  - climate
  - EDA
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```










## Introduction

What follows is an [EDA](https://en.wikipedia.org/wiki/Exploratory_data_analysis) inspired by conversations I've had about Berlin's changing climate, something I've personally witnessed in the 11+ years that I've lived here. Part of my motivation also stems from a running disagreement obout the direction of that change: My wife, for example. thinks June is a sorry excuse for a summer month, and that it used to be nicer, and I think she might be imagining things. In the end we might both have to modify our positions a bit.

Beyond mere curosity and [Besserwisserei](https://www.dict.cc/deutsch-englisch/Besserwisser.html), I think it's important to explore how global warming and climate change manifest themselves at the local level. Climate change is happening [now](https://climate.nasa.gov/effects/), and there's some evidence that it's accelerating even [faster than predicted](https://www.theguardian.com/world/2018/aug/21/arctics-strongest-sea-ice-breaks-up-for-first-time-on-record). 

For the record, I'm neither a climatoligist nor a meteorologist, and nothing about my analysis is going to be cutting edge or original. I'll also avoid making too many inferences based on the data, limiting myself instead to exploration. That having been said, I should still be able draw some conclusions, however tentative.

The next couple of sections cover how I wrangle the data into a more manageable form. If you're not interested in that kind of thing, [skip to the analysis](#analysis).




***




## Data Import and Preparation

First off, the libraries:

```{r load libs, warning=FALSE, error=FALSE, message=FALSE}
library(readr)
library(dplyr)
library(tidyr)
library(stats)
library(psych)
library(lubridate)
library(ggplot2)
library(corrplot)
```

The data is a subset of the [Deutscher Wetterdienst](https://www.dwd.de/DE/leistungen/klimadatendeutschland/klarchivtagmonat.html)'s
extensive repository of weather data. It's possible to get hourly measurements, going back decades, but I decided daily averages were enough for this analysis. Downloading the data programmatically from the DWD archive interface would have been horribly complex, so I did it the old-fashioned way: I downloaded the data as four ZIPs (from four Berlin weather stations), extracted the TXT/CSV files, renamed them to something more descriptive, and wrote some code to remove some excess white space that was interfering with the data import.

*Edit*: While putting the final touches on this post I discovered that the DWD offers FTP access to their databases via the [Climate Data Center](ftp://ftp-cdc.dwd.de/pub/CDC/).

The data files are semicolon-delimited. To keep things simple I'll import everything as character strings. Numeric and date objects are converted later, as needed. The value `-999` is imported as `NA`.

```{r remove whitespace, message=FALSE}
# get the names of  the data files, import them as text, remove white space and
# overwrite originals with de-whitespaced files
data_path <- file.path("datasets", "berlin_climate_data")
file_names <- dir(data_path)
file_names <- file_names[grep(pattern = "data", file_names)]

for (file_name in file_names){
    file_path <- file.path(data_path, file_name)
    file <- read_file(file_path)
    file <- gsub(" ", "", file)
    write_file(file, file_path)
}

# wrapper function to load data with defaults
read_data <- function(path){
    read_delim(file = path,
               delim = ";",
               col_types = paste0(rep("c", 19), collapse = ""),
               na = "-999"
               )
}

# read in the data
dahlem_fu_data <- read_data(file.path(data_path, "Dahlem-(FU)-data.txt"))
dahlem_lfag_data <- read_data(file.path(data_path, "Dahlem-(LFAG)-data.txt"))
tegel_data <- read_data(file.path(data_path, "Tegel-data.txt"))
tempelhof_data <- read_data(file.path(data_path, "Tempelhof-data.txt"))
```


It makes sense to take a look at the included parameter files to get an idea what kind of data I'm working with. These are in German (umlauts!), so I'll use `guess_encoding()` from the `readr` library to figure out which ISO I need.

```{r guess file encoding}
guess_encoding("datasets/berlin_climate_data/Dahlem-(FU)-params.txt") %>% 
    knitr::kable()
```

ISO-8859-1 it is. I don't care too much about the details of each station, so I'll just import one file, `Tempelhof-params.txt`, to gain some insight into the parameters, i.e. abbreviations, units used, etc. 

```{r load and show params, warning=FALSE}
# load parameter file
data_path <- file.path("datasets", "berlin_climate_data", "Tempelhof-params.txt")
tempelhof_params <- read_delim(file = data_path,
                               delim = ";",
                               col_types = paste0(rep("c", 13), collapse = ""),
                               locale = locale(encoding = "ISO-8859-1")
                               )

# filter and show parameters
tempelhof_params %>%
    select(2:7) %>% 
    filter(!duplicated(Parameter) & !is.na(Parameter)) %>% 
    knitr::kable()
```





### Tidying the Data

There are a couple more changes to be made before I can start visualizing. First, [tidyverse](https://www.tidyverse.org/) magic works most potently on *long* data, but the DW uses *wide* format ([see the difference here](https://en.wikipedia.org/wiki/Wide_and_narrow_data)). Second, the variable abbreviations are hard to understand (FM, RSK, etc.), so I should replace them with something else. Third and last, I now have four datasets, one for each Berlin weather station, but one would be preferable.

I'll change the variable names using the following map.

```{r variable names map}
var_names <- c("Date" = "MESS_DATUM",
               "Avg. Wind Speed (m/sec)" = "FM",
               "Max Wind Speed (m/sec)" = "FX",
               "Avg. Cloud Cover (8th)" = "NM",
               "Avg. Air Pressure (hPa)" = "PM",
               "Precipitation (mm)" = "RSK",
               "Sun Shine Duration (h)" = "SDK",
               "Snow (cm)" = "SHK_TAG",
               "Avg. Temp. (°C)" = "TMK",
               "Min. Temp. (°C)" = "TNK",
               "Max Temp. (°C)" = "TXK",
               "Avg. Humidity (%)" = "UPM"
               )
```

The following `tidy_data` function reduces each data frame to the set of variables I'm interested in, converts the character strings to numbers and dates, and `gathers` the variables into long format.

```{r tidy_data function}
tidy_data <- function(df, vars, station_name){
    df <- select(df, vars)
    df <- as_tibble(sapply(df, as.double))
    df$Date <- ymd(df$Date)
    df <- gather(df, key = "Variable", value = "Value", 2:12)
    df$Station <- station_name
    df
}
```

I can now call `tidy_data` for each station, and then combine the station data into one data frame `berlin_data`.

```{r tidy stations}
# call tidy_data for each station dataset
dahlem_lfag_data <- tidy_data(dahlem_lfag_data, var_names, "Dahlem (LFAG)")
dahlem_fu_data <- tidy_data(dahlem_fu_data, var_names, "Dahlem (FU)")
tegel_data <- tidy_data(tegel_data, var_names, "Tegel")
tempelhof_data <- tidy_data(tempelhof_data, var_names, "Tempelhof")

# combine station data into one data frame
berlin_data <- rbind(dahlem_lfag_data, dahlem_fu_data, tegel_data, tempelhof_data)
```

There's just one final change I'd like to make: The values reflect daily averages, and measurement began in the 19th century for some stations, so I'm faced with hundreds of thousands of observations! To make things more manageable I'll include different time scales, e.g. years, months, weeks, days, and [meteorological seasons](https://en.wikipedia.org/wiki/Season#Meteorological). While I'm at it I'll also convert months and seasons to factors.

```{r add year month week season}
# add years, months, weeks, days, and seasons
berlin_data <- berlin_data %>% 
    mutate(Year = year(Date),
           Month = month(Date),
           Week = week(Date),
           Day = day(Date),
           Season = case_when(Month %in% c(12, 1, 2) ~ "Winter",
                              Month %in% 3:5 ~ "Spring",
                              Month %in% 6:8 ~ "Summer",
                              Month %in% 9:11 ~ "Fall",
                              )
           )

# turn seasons into factors
berlin_data$Season <- factor(berlin_data$Season,
                             ordered = T,
                             levels = c("Spring", "Summer", "Winter", "Fall")
                             )

# turn months into factors
berlin_data$Month <- factor(berlin_data$Month,
                            ordered = T,
                            levels = 1:12,
                            labels = c("January", "February", "March", "April",
                                       "May", "June", "July", "August", 
                                       "September", "October", "November",
                                       "December"
                                       )
                            )
```




***



## <a name="analysis"></a>Visualizing Climate Change in Berlin

I now have a few hundred thousand observations for each of four Berlin weather stations, which I can freely group based on my analytical needs. The following table shows the total observations (daily averages) for each of Berlin's four weather stations.

```{r show number of observations}
berlin_data %>% 
    group_by(Station) %>% 
    summarise("number of observations" = n()) %>% 
    knitr::kable()
```

Let's first take a look at how average yearly temperatures have changed since 1876. The following time series shows that average yearly temperatures in Berlin have increased by about 2°C since the middle of the 20th century, although there is a fair amount of year-by-year variation.
 
```{r viz mean yearly temps, message=FALSE}
# create variable to hold theme (reusable)
thm <- theme_minimal() + 
    theme(panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank()
          )

# generate combined timeseries of temperatur data
berlin_data %>% 
    filter(Variable == "Avg. Temp. (°C)") %>%
    group_by(Station, Year) %>% 
    summarise(Value = mean(Value, na.rm = T)) %>%
    ggplot(aes(x = Year, y = Value)) +  
    geom_line(aes(color = Station)) +
    geom_smooth(se = F, method = "loess", span = .2) +
    labs(title = "Avg. Yearly Temperature (°C), 1876-2017",
         y = "Temp."
         ) +
    thm +
    scale_x_continuous(limits = c(1876, 2017),
                       breaks = seq(1877, 2017, by = 10)
                       ) +
    scale_y_continuous(limits = c(3, 12),
                       breaks = seq(3, 12, by = 1)
                       )
```

Also conspicuous is the precipitous drop in 1945. Histograms of each year from 1941-1949 reveal bimodal distributions of daily temperatures for most years. One mode is missing from 1945, that is to say, some data is missing, and the data that is available clusters around the low end.

```{r viz distribution of temps 1941-1949}
berlin_data %>% 
    filter(Station == "Dahlem (LFAG)",
           Variable == "Avg. Temp. (°C)",
           Year %in% 1941:1949,
           !is.na(Value)
           ) %>% 
    ggplot(aes(x = Value)) + 
    geom_histogram(bins = 30) +
    facet_wrap(~Year) + 
    theme_minimal() + 
    theme(panel.grid.minor = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.spacing = unit(2, "lines")
          ) +
    labs(title = "Distribution of Annual Temperatures (°C), 1941-1949",
         x = "Temperature"
         )
```

A table observation counts (i.e. number of daily averages) confirms that 1945 is missing data.

```{r}
berlin_data %>% 
    filter(Station == "Dahlem (LFAG)",
           Variable == "Avg. Temp. (°C)",
           Year %in% 1941:1949,
           !is.na(Value)
           ) %>% 
    group_by(Year) %>% 
    summarize("number of obs." = n(),
              "annual avg. temp." = mean(Value)) %>% 
    knitr::kable()
```

The [Battle of Berlin](https://en.wikipedia.org/wiki/Battle_of_Berlin) was in the spring of 1945, so there's really no question as to why the data is missing. I could go to the trouble of interpolating values from the flanking years, but I'll save myself some time and just drop 1945 instead, which shouldn't have any effect on the overall trend. I'll also aggregate the station data to make later visualizations a little easier.

```{r drop 1945}
berlin_data <- berlin_data <- filter(berlin_data, Year != 1945) %>% 
    group_by(Year, Month, Week, Day, Season, Date, Variable) %>% 
    summarise(Value = mean(Value, na.rm = T)) %>% 
    ungroup()
```

The next chart compares changes in Berlin's average yearly temperature with global temperature shifts. First, I need to download some data of global historical temperatures from [NASA](https://climate.nasa.gov/vital-signs/global-temperature/).

```{r dowload nasa temp data}
nasa_data <- read_tsv("https://climate.nasa.gov/system/internal_resources/details/original/647_Global_Temperature_Data_File.txt",
                      col_names = c("Year", "World", "lowess"),
                      col_types = "idd"
                      )
```


I can then combine the NASA data with the Berlin data and visualize them together. The following graph shows the trend in mean global temperatures compared to Berlin. Note that the y-axis displays average annual temperature *change* in °C, and *not* average annual temperature. What I call change NASA calls **annual average anomaly**, which is the "change in global surface temperature relative to 1951-1980 average temperatures". To maintain consistency with NASA's data I'll also transform the Berlin data to represent the change from the 1951-1980 average. Also note that I plot Loess curves with `span = 0.2` to cut out some of the noise.

```{r viz global and local temp change}
berlin_data %>%
    filter(Variable == "Avg. Temp. (°C)",
           ) %>%
    group_by(Year) %>%
    summarise(Value = mean(Value, na.rm = T)) %>%
    
    # put Berlin data in relation to 1951-1980 average
    mutate(Berlin = Value - mean(filter(.data = .,
                                        Year %in% 1951:1980
                                        )[["Value"]]
                                 )
           ) %>%  
    right_join(nasa_data, by = "Year") %>%
    select(Year, Berlin, World) %>%
    filter(!is.na(Berlin), !is.na(World)) %>% 
    
    # loess transform
    mutate(Berlin = predict(loess(Berlin ~ Year, data = ., span = 0.2)),
           World = predict(loess(World ~ Year, data = ., span = 0.2))
           ) %>% 
    
    # tidy and plot
    gather(key = "Scope", value = "Value", 2:3) %>%
    ggplot(aes(x = Year, y= Value)) +
    geom_line(aes(color = Scope), size = 1) +
    geom_hline(yintercept = 0, linetype = 8) +
    thm + 
    scale_x_continuous(limits = c(1876, 2017),
                       breaks = seq(1877, 2017, by = 10)
                       ) +
    scale_y_continuous(limits = c(-1, 2),
                       breaks = seq(-1, 2, .5)) +
    scale_color_manual(values = c("red", "blue")) +
    labs(color = "",
         title = "Temp. Change in °C (LOESS), World vs. Berlin, 1877-2017",
         y = "Change (°C)"
         )
```

The upward trend in mean annual temperatures in Berlin broadly parallels that of the global aggregate. Interestingly, temperatures seem to be increasing faster in Berlin: average annual temperature has increased by about 2°C since 1925, compared to 1°C globally.





### Proportion of +25°C Days

Next, I would like to see how the increase in average annual temperature has affected the high end of the overall distribution of annual temperatures. The following bit of code stores just some useful, reusable settings.

```{r}
filter_group <- function(df){
    df %>% filter(Year %in% (1957:2017)) %>%
    group_by(Year, Month)
    }
    
gg_geoms_x_scale <- function(df){
    df %>% ggplot(aes(x = Year, y = Value, color = Month)) +
        geom_line(alpha = .25) +
        geom_smooth(method = "loess", se = F) +
        scale_x_continuous(limits = c(1957, 2017),
                           breaks = seq(1957, 2017, by = 10)
                           ) +
        facet_wrap(~ Month)
}

thm <- thm + 
    theme(legend.position = "none",
          panel.spacing = unit(1, "lines")
          )
```

Now to plot the *proportion* of days per month, for the months May-September, where maximum temperatures exceed 25°C. I've excluded months where temperatures almost never reach 25°.

```{r temperatures greater that 25C}
berlin_data %>% 
    filter(Variable == "Max Temp. (°C)",
           Month %in% c("May", "June", "July", "August", "September")
           ) %>%
    filter_group() %>% 
    summarise(Value = sum(Value > 25)/n()) %>% 
    gg_geoms_x_scale() +
    scale_y_continuous(limits = c(0, 1),
                       breaks = seq(0, 1, by = .1)
                       ) +
    thm +
    labs(title = "Proportion of Days with Temp. > 25°C, 1957-2017",
         y = "Proportion"
         )
```

Predictably, the proportion of summer days with maximum temperatures above 25°C has gone up since 1957. It is, nevertheless, interesting to see the variation over the years, as well as across the months. For July and August, for instance, the number has nearly doubled, equating to about a week more of very warm days. These two months also show somewhat more yearly variation compared to the others. June has, oddly, remained fairly stable.





### Sunshine

Looking at the next plot, the average number of hours of daily sunshine appears to have remained fairly stable at least since 1977. There is some fluctuation, but there is no clear trend in any direction. I take this to mean that these months have not become significantly more overcast (or, conversely, sunnier) - at least, not over the long term.

```{r avg. daily sunshine by month, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Sun Shine Duration (h)") %>%
    filter_group() %>% 
    summarize(Value = mean(Value)) %>% 
    gg_geoms_x_scale() +
    scale_y_continuous(limits = c(0, 12.5),
                       breaks = seq(0, 12, by = 1)
                       ) +
    facet_wrap(~ Month) +
    thm +
    labs(title = "Avg. Daily Sunshine (Hours), 1957-2017",
         y= "Duration (h)"
         )
```






### Precipitation

For the most part the average amount of precipitation also doesn't show any general upward trend since 1957. At shorter timescales, however, and for individual months, there are discernible trends. June and July - and to a lesser degree, October - show a clear increase in the amound of precipitation. 

```{r avg. daily precipitation by month, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Precipitation (mm)") %>%
    filter_group() %>% 
    summarize(Value = mean(Value)) %>% 
    gg_geoms_x_scale() + 
    scale_y_continuous(limits = c(0, 8),
                       breaks = seq(0, 8, by = 1)) +
    facet_wrap(~ Month) +
    thm + 
    labs(title = "Avg. Daily Precipitation (mm), 1957-2017",
         y= "Amount (mm)"
         )
```







### Days Without Precipitation

The proportion of "wet" to "dry" days has remained relatively stable over the long term, hovering around 50% for every month since 1957. There are some discernible trends over shorter timescales of 10-20 years: upwards in the late winter and early spring (i.e. more "dry" days), and downwards for the winter months, as well as for July (i.e. more "wet" days).

```{r proportion days without precipitation by month, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Precipitation (mm)") %>%
    filter_group() %>% 
    summarize(Value = sum(Value == 0)/n()) %>% 
    gg_geoms_x_scale() + 
    scale_y_continuous(limits = c(0, 1),
                       breaks = seq(0, 1, by = .1)) +
    thm +
    labs(title = "Days Without Precipitation as Proportion of all Days, 1957-2017",
         y= "Proportion"
         )
```







### Air Pressure

Given what I know about the dynamic between air pressure and weather - which is admittedly not that much - I think air pressure could be a further indicator of storm intensity. As I understand it, stable high pressure zones usually indicate good weather while rapidly decreasing air pressure indicates an impending storm. Hourly data are necessary to properly analyze the association between air pressure and bad weather, something I decided against for the this analysis for time reasons. Still, I assume strong storms would leave some trace by driving down daily averages. 

To see if air pressure, measured in hectopascals (hPa), is a good indicator of weather conditions, I'll plot the correlations of some relevant variables in a correlogram. I should note that this probably isn't the best method to determine how air pressure affects weather. It's more of a heuristic to help me determine if there is a question here worth answering. Finer-grained air pressure data and variables more closely associated with bad weather, cloud type for instance, in addition to more rigorous statistical methods would allow me to more confidently draw conclusions. But that's a project for another day.

First I need to compute a correlation matrix, which requires some transformation. This code *widens* the data by giving each variable it's own column (basically the reverse of the above *tidying* process), and then computes the correlations (Spearman's $\rho$ in this case).

```{r transform and subset data and do correlation}
berdat_sub <- berlin_data %>%
    filter(Month %in% c("May", "June", "July", "August", "September"),
           Year > 1956) %>%
    spread(Variable, Value) %>% 
    select(7:17, -`Snow (cm)`, -`Avg. Cloud Cover (8th)`)

names(berdat_sub) <- c("PRESS", "HUMID", "TEMP_AVG", "WIND_AVG", "TEMP_MAX",
                       "WIND_MAX", "TEMP_MIN", "PRECIP", "SUN")

berdat_cortest <- corr.test(x = berdat_sub, method = "spearman")
```

I'll use a matrix of p-values, conveniently calculated by the `psych` library's `corr.test` function, to test for the statistical significance of the individual correlations, as even low correlation can hint at so sort of association. The significance level is set to $\alpha$ = 0.001. (**Note**: An outcome is "statistically significant" when the probability of a chance occurence, given by a p-value, is less than $\alpha$, i.e. *very* small.)

```{r correlogram of selected variables, fig.width=7, fig.height=7}
corrplot(berdat_cortest$r,
         p.mat = berdat_cortest$p,
         sig.level = .001,
         type = "upper",
         method = "number",
         order = "AOE",
         tl.cex = .8,
         title = "Correlogram (rho) of Selected Variables",
         mar = c(0, 0, 2, 0),
         col = colorRampPalette(c("red", "white", "blue"))(100)
         )
```


Of particular interest are correlations between `PRESS` and the other variables that also make intuitive sense, as that would imply that air pressure is a good predictor of weather conditions. We should expect, for example, that high pressure is positively correlated with fair weather, as given by `SUN`, and negatively correlated with wind and bad weather, as given by `WIND_MAX`, `WIND_AVG`, and `PRECIP`. Looking at the plot, this seems to be the case, so I'll accept, with the above proviso, that a day's average air pressure can tell me something about the weather conditions for that day.

The final plot displays the number of days per month where there is at least a -3 hPa *drop* in air pressure compared to the previous day. Although this measure is obviously not perfect, my layperson intuition tells me that an increase in the number of such drops might hint at an increase in storm fronts of a certain intensity.

The choice of a -3 hPa drop is not completely arbitrary. A convenient table on [bohlken.net](http://www.bohlken.net/airpressure2.htm) (a barograph maker) states that a drop of -3 hPa can lead to strong winds of 6-7 Bfts (11-17 m/s), so it seems like a decent place to start.

The final plot contains the number of days per month with a difference of at least -3 hPa compared to the previous day. There are at least two major problems here: First, the table on bohlken.net relates wind speed increases to a drop in air pressure over a 1-3 hour timeframe, while the data I'm using contains 24-hour means. Second, there is an implicit assumption that bad weather days and good weather days are more or less evenly dispersed, as there wouldn't otherwise be any difference between consecutive days of the same type. This is very likely not the case.

Still, I'm fairly confident that larger, more extreme storm fronts would leave a trace on daily hPa averages, and that an increase in the amount or intensity of these fluctuations is measurable. I also think that severe weather is still infrequent enough in Berlin that an increasing number of large drops should show up in monthly aggregates.

The plot below seems to confirm my intuitions. Especially the months May-August show strong upward trends over the last 10-15 years, which one might interpret as an increase in the number of storms of a certain magnitude. This is also consistent with my understanding of how temperature, air pressure, and storm systems relate: The warmer the air, the more water vapor it contains, and the more intense the resulting storms.


```{r drop in air pressure greater than -3, fig.height=10, fig.width=10}
berlin_data %>% 
    filter(Variable == "Avg. Air Pressure (hPa)") %>% 
    filter_group() %>% 
    mutate(Value = (Value - lag(Value))) %>%
    filter(!is.na(Value), Value < -3) %>%
    group_by(Year, Month) %>%
    summarize(Value = n()) %>%
    gg_geoms_x_scale() + 
    facet_wrap(~ Month) +
    scale_y_continuous(limits = c(2, 15),
                       breaks = seq(2, 15, by = 1)
                       ) +
    thm + 
    labs(title = "Drop in Air Pressure (hPa) from Previous Day > 3",
         y= "Number of Days"
         )
```









## Conclusion

If there is one conclusion that I can confidently draw from the above analysis, it is that Berlin is getting warmer at a rate on par with global average. It is also [well known](https://earthobservatory.nasa.gov/Features/ClimateStorms/page2.php) that temperature has an effect on weather systems generally, and storm intensity specifically. In an attempt to find some evidence of such a development in Berlin I analysed temperature, including the number of days per month with highs over 25°C, the average amount of monthly precipitation, the proportion of "dry" to "wet" days, and air pressure shifts as in indication of increasing storm intensity and frequency.

Taken together, these variables *suggest* that Berlin is experiencing a 10 to 20 year trend of more extreme weather: Hotter summers punctuated by more intense summer storms. I've deduced this from the following:

* Average precipitation has increased without a corresponding increase in the proportion of days with precipitation to those without.
* Daily averages of sunshine duration have, much like the the number of rainless days, remained fairly stable.
* There is a consistent increase in the number of monthly drops in air pressure of a magnitude greater than 3 hPa.

None





